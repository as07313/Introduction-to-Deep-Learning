{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Qye42z6w1V"
      },
      "source": [
        "# CS 316 : Introduction to Deep Learning - Fall 2024\n",
        "## Lab 10 : Convolutional Neural Networks\n",
        "### Dr. Abdul Samad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhl9elIZ6yyg"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "1. Make a copy of this notebook on google colab at start of the lab.\n",
        "\n",
        "2. Please rename your notebook as *Lab_10_aa12345.ipynb* before starting the lab. Notebooks which do not follow appropriate naming convention will not be graded.\n",
        "\n",
        "3. You have to submit this lab during the lab timings. You are allowed to submit till 11:59 PM on the day of your lab with a 30% penalty. No submissions will be accepted afterwards.\n",
        "\n",
        "4. At the end of the lab, download the notebook (ipynb extension file) and upload it on canvas as a file. Submitting link to notebook or any other file will not be accepted.\n",
        "\n",
        "5. Each task has points assigned to it. Total Lab is of 100 points.\n",
        "\n",
        "6. Use of for loops is strictly prohibited.\n",
        "\n",
        "7. For every theoretical question, there is a separate cell given at the end. You have to write your answer there.\n",
        "\n",
        "8. If you have any questions, please feel free to reach out to the course instructor or RA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqAoTxi37G4h"
      },
      "source": [
        "## Task Overview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH1lujCImySb"
      },
      "source": [
        "In this lab we will work on CNNs. This Lab is going to be short. Work through the cells below, running each cell in turn. In various places you will see the words \"TODO\". Follow the instructions at these places and make predictions about what is going to happen or write code to complete the functions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with importing Libraries first"
      ],
      "metadata": {
        "id": "ewjpobC0x20G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYMZ1x-Pv1ht"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convolution for MNIST**\n",
        "\n",
        "This notebook builds a proper network for 2D convolution.  It works with the MNIST dataset , which was the original classic dataset for classifying images.  The network will take a 28x28 grayscale image and classify it into one of 10 classes representing a digit.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZKzvoaLyiwav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this once to load the train and test data straight into a dataloader class\n",
        "# that will provide the batches\n",
        "\n",
        "# (It may complain that some files are missing because the files seem to have been\n",
        "# reorganized on the underlying website, but it still seems to work). If everything is working\n",
        "# properly, then the whole notebook should run to the end without further problems\n",
        "# even before you make changes.\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)"
      ],
      "metadata": {
        "id": "wScBGXXFVadm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's draw some of the training data\n",
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "be3b0e91-538f-43c8-eb59-06161dc9a064",
        "id": "GmSg6AWyiwax"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the network.  This is a more typical way to define a network than the sequential structure.  We define a class for the network, and define the parameters in the constructor.  Then we use a function called forward to actually run the network.  It's easy to see how you might use residual connections in this format."
      ],
      "metadata": {
        "id": "oIZw6WW5iway"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: TODO [30 Points]\n",
        "\n",
        "Build this network architecture by completing the function given below.\n",
        "1. A valid convolution with kernel size 5, 1 input channel and 10 output channels\n",
        "2. A max pooling operation over a 2x2 area\n",
        "3. A Relu\n",
        "4. A valid convolution with kernel size 5, 10 input channels and 20 output channels\n",
        "5. A 2D Dropout layer\n",
        "6. A max pooling operation over a 2x2 area\n",
        "7. A relu\n",
        "8. A flattening operation\n",
        "9. A fully connected layer mapping from (whatever dimensions we are at-- find out using .shape) to 50\n",
        "10. A ReLU\n",
        "11. A fully connected layer mapping from 50 to 10 dimensions\n",
        "12. A softmax function."
      ],
      "metadata": {
        "id": "Fd_M--KTAfFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.model=nn.Sequential(\n",
        "\n",
        "            #nn.MaxPool2d( kernel_size=2, stride=2) This code can be used for max pooling. Google it to understand it.\n",
        "            #nn.Dropout() can be used for dropout\n",
        "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, padding=0, stride=1),\n",
        "            nn.MaxPool2d( kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5, padding=0, stride=1),\n",
        "            nn.Dropout2d(),\n",
        "            nn.MaxPool2d( kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=320, out_features=50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=50, out_features=10),\n",
        "            nn.Softmax()\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "EQkvw2KOPVl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Do NOT EDIT\n",
        "#USE THIS CODE FOR TESTING\n",
        "#Since we can't compare the model, its better to look at the its printed structure and compare it with layers given in architecture\n",
        "net = Net()\n",
        "print(net)\n",
        "\n",
        "# Test the network with a random input of shape (batch_size, channels, height, width)\n",
        "x = torch.randn(16, 1, 28, 28)  # Example batch of 16 samples, 1 channel, 28x28 images\n",
        "output = net(x)\n",
        "print(output.shape)  # Output should be (16, 10)\n",
        "\n",
        "assert output.shape == (16, 10), \"Output shape does not match expected shape\"\n"
      ],
      "metadata": {
        "id": "a09iM1RDr9v2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f57d182-b419-4e1c-93e6-a3bfcdf89a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (4): Dropout2d(p=0.5, inplace=False)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): ReLU()\n",
            "    (7): Flatten(start_dim=1, end_dim=-1)\n",
            "    (8): Linear(in_features=320, out_features=50, bias=True)\n",
            "    (9): ReLU()\n",
            "    (10): Linear(in_features=50, out_features=10, bias=True)\n",
            "    (11): Softmax(dim=None)\n",
            "  )\n",
            ")\n",
            "torch.Size([16, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization of weights\n",
        "def weights_init(layer_in):\n",
        "  if isinstance(layer_in, nn.Linear):\n",
        "    nn.init.kaiming_uniform_(layer_in.weight)\n",
        "    layer_in.bias.data.fill_(0.0)"
      ],
      "metadata": {
        "id": "qWZtkCZcU_dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training routine\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  # Get each\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.nll_loss(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # Store results\n",
        "    if batch_idx % 10 == 0:\n",
        "      print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset), loss.item()))"
      ],
      "metadata": {
        "id": "xKQd9PzkQ766"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run on test data\n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      output = model(data)\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "Byn-f7qWRLxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create network\n",
        "model = Net()\n",
        "# Initialize model weights\n",
        "model.apply(weights_init)\n",
        "# Define optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "metadata": {
        "id": "36fbtpcRLn9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for three epochs\n",
        "n_epochs = 3\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "id": "EnVil0RLiwaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5bbf81e-8353-45f5-c34a-c20e76a2d7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000]\tLoss: -0.103207\n",
            "Train Epoch: 1 [640/60000]\tLoss: -0.107371\n",
            "Train Epoch: 1 [1280/60000]\tLoss: -0.099983\n",
            "Train Epoch: 1 [1920/60000]\tLoss: -0.107406\n",
            "Train Epoch: 1 [2560/60000]\tLoss: -0.104731\n",
            "Train Epoch: 1 [3200/60000]\tLoss: -0.127310\n",
            "Train Epoch: 1 [3840/60000]\tLoss: -0.146569\n",
            "Train Epoch: 1 [4480/60000]\tLoss: -0.118514\n",
            "Train Epoch: 1 [5120/60000]\tLoss: -0.137689\n",
            "Train Epoch: 1 [5760/60000]\tLoss: -0.168405\n",
            "Train Epoch: 1 [6400/60000]\tLoss: -0.122546\n",
            "Train Epoch: 1 [7040/60000]\tLoss: -0.203514\n",
            "Train Epoch: 1 [7680/60000]\tLoss: -0.196255\n",
            "Train Epoch: 1 [8320/60000]\tLoss: -0.161864\n",
            "Train Epoch: 1 [8960/60000]\tLoss: -0.262733\n",
            "Train Epoch: 1 [9600/60000]\tLoss: -0.216955\n",
            "Train Epoch: 1 [10240/60000]\tLoss: -0.237677\n",
            "Train Epoch: 1 [10880/60000]\tLoss: -0.238207\n",
            "Train Epoch: 1 [11520/60000]\tLoss: -0.272051\n",
            "Train Epoch: 1 [12160/60000]\tLoss: -0.229518\n",
            "Train Epoch: 1 [12800/60000]\tLoss: -0.287223\n",
            "Train Epoch: 1 [13440/60000]\tLoss: -0.340536\n",
            "Train Epoch: 1 [14080/60000]\tLoss: -0.348375\n",
            "Train Epoch: 1 [14720/60000]\tLoss: -0.375555\n",
            "Train Epoch: 1 [15360/60000]\tLoss: -0.431975\n",
            "Train Epoch: 1 [16000/60000]\tLoss: -0.400291\n",
            "Train Epoch: 1 [16640/60000]\tLoss: -0.470359\n",
            "Train Epoch: 1 [17280/60000]\tLoss: -0.402178\n",
            "Train Epoch: 1 [17920/60000]\tLoss: -0.421965\n",
            "Train Epoch: 1 [18560/60000]\tLoss: -0.383876\n",
            "Train Epoch: 1 [19200/60000]\tLoss: -0.477896\n",
            "Train Epoch: 1 [19840/60000]\tLoss: -0.520546\n",
            "Train Epoch: 1 [20480/60000]\tLoss: -0.431395\n",
            "Train Epoch: 1 [21120/60000]\tLoss: -0.387759\n",
            "Train Epoch: 1 [21760/60000]\tLoss: -0.415305\n",
            "Train Epoch: 1 [22400/60000]\tLoss: -0.388672\n",
            "Train Epoch: 1 [23040/60000]\tLoss: -0.465588\n",
            "Train Epoch: 1 [23680/60000]\tLoss: -0.552984\n",
            "Train Epoch: 1 [24320/60000]\tLoss: -0.425983\n",
            "Train Epoch: 1 [24960/60000]\tLoss: -0.349252\n",
            "Train Epoch: 1 [25600/60000]\tLoss: -0.491285\n",
            "Train Epoch: 1 [26240/60000]\tLoss: -0.357725\n",
            "Train Epoch: 1 [26880/60000]\tLoss: -0.498456\n",
            "Train Epoch: 1 [27520/60000]\tLoss: -0.576449\n",
            "Train Epoch: 1 [28160/60000]\tLoss: -0.537475\n",
            "Train Epoch: 1 [28800/60000]\tLoss: -0.486595\n",
            "Train Epoch: 1 [29440/60000]\tLoss: -0.480213\n",
            "Train Epoch: 1 [30080/60000]\tLoss: -0.497974\n",
            "Train Epoch: 1 [30720/60000]\tLoss: -0.560855\n",
            "Train Epoch: 1 [31360/60000]\tLoss: -0.463930\n",
            "Train Epoch: 1 [32000/60000]\tLoss: -0.581250\n",
            "Train Epoch: 1 [32640/60000]\tLoss: -0.493473\n",
            "Train Epoch: 1 [33280/60000]\tLoss: -0.464384\n",
            "Train Epoch: 1 [33920/60000]\tLoss: -0.588376\n",
            "Train Epoch: 1 [34560/60000]\tLoss: -0.540451\n",
            "Train Epoch: 1 [35200/60000]\tLoss: -0.556212\n",
            "Train Epoch: 1 [35840/60000]\tLoss: -0.428208\n",
            "Train Epoch: 1 [36480/60000]\tLoss: -0.546996\n",
            "Train Epoch: 1 [37120/60000]\tLoss: -0.530964\n",
            "Train Epoch: 1 [37760/60000]\tLoss: -0.617886\n",
            "Train Epoch: 1 [38400/60000]\tLoss: -0.628034\n",
            "Train Epoch: 1 [39040/60000]\tLoss: -0.557452\n",
            "Train Epoch: 1 [39680/60000]\tLoss: -0.547272\n",
            "Train Epoch: 1 [40320/60000]\tLoss: -0.587595\n",
            "Train Epoch: 1 [40960/60000]\tLoss: -0.542640\n",
            "Train Epoch: 1 [41600/60000]\tLoss: -0.572233\n",
            "Train Epoch: 1 [42240/60000]\tLoss: -0.541805\n",
            "Train Epoch: 1 [42880/60000]\tLoss: -0.596873\n",
            "Train Epoch: 1 [43520/60000]\tLoss: -0.550533\n",
            "Train Epoch: 1 [44160/60000]\tLoss: -0.579826\n",
            "Train Epoch: 1 [44800/60000]\tLoss: -0.592130\n",
            "Train Epoch: 1 [45440/60000]\tLoss: -0.649641\n",
            "Train Epoch: 1 [46080/60000]\tLoss: -0.505320\n",
            "Train Epoch: 1 [46720/60000]\tLoss: -0.575498\n",
            "Train Epoch: 1 [47360/60000]\tLoss: -0.582775\n",
            "Train Epoch: 1 [48000/60000]\tLoss: -0.635094\n",
            "Train Epoch: 1 [48640/60000]\tLoss: -0.707801\n",
            "Train Epoch: 1 [49280/60000]\tLoss: -0.639023\n",
            "Train Epoch: 1 [49920/60000]\tLoss: -0.582488\n",
            "Train Epoch: 1 [50560/60000]\tLoss: -0.576870\n",
            "Train Epoch: 1 [51200/60000]\tLoss: -0.582062\n",
            "Train Epoch: 1 [51840/60000]\tLoss: -0.545241\n",
            "Train Epoch: 1 [52480/60000]\tLoss: -0.496153\n",
            "Train Epoch: 1 [53120/60000]\tLoss: -0.609825\n",
            "Train Epoch: 1 [53760/60000]\tLoss: -0.609629\n",
            "Train Epoch: 1 [54400/60000]\tLoss: -0.607425\n",
            "Train Epoch: 1 [55040/60000]\tLoss: -0.528027\n",
            "Train Epoch: 1 [55680/60000]\tLoss: -0.661191\n",
            "Train Epoch: 1 [56320/60000]\tLoss: -0.644699\n",
            "Train Epoch: 1 [56960/60000]\tLoss: -0.605052\n",
            "Train Epoch: 1 [57600/60000]\tLoss: -0.658042\n",
            "Train Epoch: 1 [58240/60000]\tLoss: -0.555541\n",
            "Train Epoch: 1 [58880/60000]\tLoss: -0.658708\n",
            "Train Epoch: 1 [59520/60000]\tLoss: -0.620393\n",
            "\n",
            "Test set: Avg. loss: -0.6341, Accuracy: 6419/10000 (64%)\n",
            "\n",
            "Train Epoch: 2 [0/60000]\tLoss: -0.593592\n",
            "Train Epoch: 2 [640/60000]\tLoss: -0.496646\n",
            "Train Epoch: 2 [1280/60000]\tLoss: -0.646984\n",
            "Train Epoch: 2 [1920/60000]\tLoss: -0.641910\n",
            "Train Epoch: 2 [2560/60000]\tLoss: -0.582150\n",
            "Train Epoch: 2 [3200/60000]\tLoss: -0.632727\n",
            "Train Epoch: 2 [3840/60000]\tLoss: -0.556143\n",
            "Train Epoch: 2 [4480/60000]\tLoss: -0.580799\n",
            "Train Epoch: 2 [5120/60000]\tLoss: -0.689398\n",
            "Train Epoch: 2 [5760/60000]\tLoss: -0.665085\n",
            "Train Epoch: 2 [6400/60000]\tLoss: -0.634451\n",
            "Train Epoch: 2 [7040/60000]\tLoss: -0.738963\n",
            "Train Epoch: 2 [7680/60000]\tLoss: -0.548530\n",
            "Train Epoch: 2 [8320/60000]\tLoss: -0.615123\n",
            "Train Epoch: 2 [8960/60000]\tLoss: -0.633466\n",
            "Train Epoch: 2 [9600/60000]\tLoss: -0.573282\n",
            "Train Epoch: 2 [10240/60000]\tLoss: -0.605757\n",
            "Train Epoch: 2 [10880/60000]\tLoss: -0.627182\n",
            "Train Epoch: 2 [11520/60000]\tLoss: -0.605496\n",
            "Train Epoch: 2 [12160/60000]\tLoss: -0.677214\n",
            "Train Epoch: 2 [12800/60000]\tLoss: -0.585774\n",
            "Train Epoch: 2 [13440/60000]\tLoss: -0.636308\n",
            "Train Epoch: 2 [14080/60000]\tLoss: -0.592687\n",
            "Train Epoch: 2 [14720/60000]\tLoss: -0.650787\n",
            "Train Epoch: 2 [15360/60000]\tLoss: -0.629760\n",
            "Train Epoch: 2 [16000/60000]\tLoss: -0.662839\n",
            "Train Epoch: 2 [16640/60000]\tLoss: -0.538976\n",
            "Train Epoch: 2 [17280/60000]\tLoss: -0.717891\n",
            "Train Epoch: 2 [17920/60000]\tLoss: -0.599178\n",
            "Train Epoch: 2 [18560/60000]\tLoss: -0.624264\n",
            "Train Epoch: 2 [19200/60000]\tLoss: -0.721296\n",
            "Train Epoch: 2 [19840/60000]\tLoss: -0.681700\n",
            "Train Epoch: 2 [20480/60000]\tLoss: -0.589596\n",
            "Train Epoch: 2 [21120/60000]\tLoss: -0.596297\n",
            "Train Epoch: 2 [21760/60000]\tLoss: -0.545800\n",
            "Train Epoch: 2 [22400/60000]\tLoss: -0.602633\n",
            "Train Epoch: 2 [23040/60000]\tLoss: -0.657380\n",
            "Train Epoch: 2 [23680/60000]\tLoss: -0.659842\n",
            "Train Epoch: 2 [24320/60000]\tLoss: -0.675961\n",
            "Train Epoch: 2 [24960/60000]\tLoss: -0.646572\n",
            "Train Epoch: 2 [25600/60000]\tLoss: -0.573657\n",
            "Train Epoch: 2 [26240/60000]\tLoss: -0.619807\n",
            "Train Epoch: 2 [26880/60000]\tLoss: -0.619317\n",
            "Train Epoch: 2 [27520/60000]\tLoss: -0.739099\n",
            "Train Epoch: 2 [28160/60000]\tLoss: -0.596365\n",
            "Train Epoch: 2 [28800/60000]\tLoss: -0.574749\n",
            "Train Epoch: 2 [29440/60000]\tLoss: -0.537833\n",
            "Train Epoch: 2 [30080/60000]\tLoss: -0.578862\n",
            "Train Epoch: 2 [30720/60000]\tLoss: -0.550377\n",
            "Train Epoch: 2 [31360/60000]\tLoss: -0.590842\n",
            "Train Epoch: 2 [32000/60000]\tLoss: -0.633281\n",
            "Train Epoch: 2 [32640/60000]\tLoss: -0.564825\n",
            "Train Epoch: 2 [33280/60000]\tLoss: -0.652067\n",
            "Train Epoch: 2 [33920/60000]\tLoss: -0.681174\n",
            "Train Epoch: 2 [34560/60000]\tLoss: -0.612127\n",
            "Train Epoch: 2 [35200/60000]\tLoss: -0.547758\n",
            "Train Epoch: 2 [35840/60000]\tLoss: -0.554884\n",
            "Train Epoch: 2 [36480/60000]\tLoss: -0.607859\n",
            "Train Epoch: 2 [37120/60000]\tLoss: -0.557137\n",
            "Train Epoch: 2 [37760/60000]\tLoss: -0.693735\n",
            "Train Epoch: 2 [38400/60000]\tLoss: -0.601803\n",
            "Train Epoch: 2 [39040/60000]\tLoss: -0.642365\n",
            "Train Epoch: 2 [39680/60000]\tLoss: -0.628209\n",
            "Train Epoch: 2 [40320/60000]\tLoss: -0.521320\n",
            "Train Epoch: 2 [40960/60000]\tLoss: -0.668787\n",
            "Train Epoch: 2 [41600/60000]\tLoss: -0.667850\n",
            "Train Epoch: 2 [42240/60000]\tLoss: -0.672650\n",
            "Train Epoch: 2 [42880/60000]\tLoss: -0.726230\n",
            "Train Epoch: 2 [43520/60000]\tLoss: -0.646062\n",
            "Train Epoch: 2 [44160/60000]\tLoss: -0.609399\n",
            "Train Epoch: 2 [44800/60000]\tLoss: -0.632421\n",
            "Train Epoch: 2 [45440/60000]\tLoss: -0.615721\n",
            "Train Epoch: 2 [46080/60000]\tLoss: -0.608057\n",
            "Train Epoch: 2 [46720/60000]\tLoss: -0.607487\n",
            "Train Epoch: 2 [47360/60000]\tLoss: -0.570397\n",
            "Train Epoch: 2 [48000/60000]\tLoss: -0.700603\n",
            "Train Epoch: 2 [48640/60000]\tLoss: -0.568858\n",
            "Train Epoch: 2 [49280/60000]\tLoss: -0.636445\n",
            "Train Epoch: 2 [49920/60000]\tLoss: -0.600512\n",
            "Train Epoch: 2 [50560/60000]\tLoss: -0.653282\n",
            "Train Epoch: 2 [51200/60000]\tLoss: -0.667861\n",
            "Train Epoch: 2 [51840/60000]\tLoss: -0.621640\n",
            "Train Epoch: 2 [52480/60000]\tLoss: -0.644561\n",
            "Train Epoch: 2 [53120/60000]\tLoss: -0.650620\n",
            "Train Epoch: 2 [53760/60000]\tLoss: -0.590891\n",
            "Train Epoch: 2 [54400/60000]\tLoss: -0.646925\n",
            "Train Epoch: 2 [55040/60000]\tLoss: -0.623633\n",
            "Train Epoch: 2 [55680/60000]\tLoss: -0.551176\n",
            "Train Epoch: 2 [56320/60000]\tLoss: -0.627207\n",
            "Train Epoch: 2 [56960/60000]\tLoss: -0.731437\n",
            "Train Epoch: 2 [57600/60000]\tLoss: -0.667470\n",
            "Train Epoch: 2 [58240/60000]\tLoss: -0.608678\n",
            "Train Epoch: 2 [58880/60000]\tLoss: -0.590281\n",
            "Train Epoch: 2 [59520/60000]\tLoss: -0.603970\n",
            "\n",
            "Test set: Avg. loss: -0.6551, Accuracy: 6569/10000 (66%)\n",
            "\n",
            "Train Epoch: 3 [0/60000]\tLoss: -0.673351\n",
            "Train Epoch: 3 [640/60000]\tLoss: -0.644786\n",
            "Train Epoch: 3 [1280/60000]\tLoss: -0.607153\n",
            "Train Epoch: 3 [1920/60000]\tLoss: -0.668159\n",
            "Train Epoch: 3 [2560/60000]\tLoss: -0.690844\n",
            "Train Epoch: 3 [3200/60000]\tLoss: -0.582164\n",
            "Train Epoch: 3 [3840/60000]\tLoss: -0.664863\n",
            "Train Epoch: 3 [4480/60000]\tLoss: -0.601422\n",
            "Train Epoch: 3 [5120/60000]\tLoss: -0.603438\n",
            "Train Epoch: 3 [5760/60000]\tLoss: -0.649007\n",
            "Train Epoch: 3 [6400/60000]\tLoss: -0.495652\n",
            "Train Epoch: 3 [7040/60000]\tLoss: -0.650812\n",
            "Train Epoch: 3 [7680/60000]\tLoss: -0.600907\n",
            "Train Epoch: 3 [8320/60000]\tLoss: -0.706204\n",
            "Train Epoch: 3 [8960/60000]\tLoss: -0.702101\n",
            "Train Epoch: 3 [9600/60000]\tLoss: -0.648198\n",
            "Train Epoch: 3 [10240/60000]\tLoss: -0.584001\n",
            "Train Epoch: 3 [10880/60000]\tLoss: -0.689950\n",
            "Train Epoch: 3 [11520/60000]\tLoss: -0.648432\n",
            "Train Epoch: 3 [12160/60000]\tLoss: -0.657449\n",
            "Train Epoch: 3 [12800/60000]\tLoss: -0.652244\n",
            "Train Epoch: 3 [13440/60000]\tLoss: -0.591652\n",
            "Train Epoch: 3 [14080/60000]\tLoss: -0.626014\n",
            "Train Epoch: 3 [14720/60000]\tLoss: -0.613761\n",
            "Train Epoch: 3 [15360/60000]\tLoss: -0.692860\n",
            "Train Epoch: 3 [16000/60000]\tLoss: -0.677456\n",
            "Train Epoch: 3 [16640/60000]\tLoss: -0.611186\n",
            "Train Epoch: 3 [17280/60000]\tLoss: -0.649476\n",
            "Train Epoch: 3 [17920/60000]\tLoss: -0.665655\n",
            "Train Epoch: 3 [18560/60000]\tLoss: -0.643809\n",
            "Train Epoch: 3 [19200/60000]\tLoss: -0.640045\n",
            "Train Epoch: 3 [19840/60000]\tLoss: -0.547419\n",
            "Train Epoch: 3 [20480/60000]\tLoss: -0.644751\n",
            "Train Epoch: 3 [21120/60000]\tLoss: -0.678969\n",
            "Train Epoch: 3 [21760/60000]\tLoss: -0.598283\n",
            "Train Epoch: 3 [22400/60000]\tLoss: -0.701652\n",
            "Train Epoch: 3 [23040/60000]\tLoss: -0.750500\n",
            "Train Epoch: 3 [23680/60000]\tLoss: -0.714548\n",
            "Train Epoch: 3 [24320/60000]\tLoss: -0.703283\n",
            "Train Epoch: 3 [24960/60000]\tLoss: -0.664622\n",
            "Train Epoch: 3 [25600/60000]\tLoss: -0.654950\n",
            "Train Epoch: 3 [26240/60000]\tLoss: -0.663775\n",
            "Train Epoch: 3 [26880/60000]\tLoss: -0.652749\n",
            "Train Epoch: 3 [27520/60000]\tLoss: -0.759471\n",
            "Train Epoch: 3 [28160/60000]\tLoss: -0.648822\n",
            "Train Epoch: 3 [28800/60000]\tLoss: -0.649569\n",
            "Train Epoch: 3 [29440/60000]\tLoss: -0.608737\n",
            "Train Epoch: 3 [30080/60000]\tLoss: -0.639782\n",
            "Train Epoch: 3 [30720/60000]\tLoss: -0.698183\n",
            "Train Epoch: 3 [31360/60000]\tLoss: -0.546126\n",
            "Train Epoch: 3 [32000/60000]\tLoss: -0.531322\n",
            "Train Epoch: 3 [32640/60000]\tLoss: -0.614855\n",
            "Train Epoch: 3 [33280/60000]\tLoss: -0.598643\n",
            "Train Epoch: 3 [33920/60000]\tLoss: -0.699344\n",
            "Train Epoch: 3 [34560/60000]\tLoss: -0.610946\n",
            "Train Epoch: 3 [35200/60000]\tLoss: -0.725935\n",
            "Train Epoch: 3 [35840/60000]\tLoss: -0.609099\n",
            "Train Epoch: 3 [36480/60000]\tLoss: -0.637292\n",
            "Train Epoch: 3 [37120/60000]\tLoss: -0.604215\n",
            "Train Epoch: 3 [37760/60000]\tLoss: -0.626605\n",
            "Train Epoch: 3 [38400/60000]\tLoss: -0.605023\n",
            "Train Epoch: 3 [39040/60000]\tLoss: -0.687590\n",
            "Train Epoch: 3 [39680/60000]\tLoss: -0.634537\n",
            "Train Epoch: 3 [40320/60000]\tLoss: -0.683238\n",
            "Train Epoch: 3 [40960/60000]\tLoss: -0.679144\n",
            "Train Epoch: 3 [41600/60000]\tLoss: -0.672147\n",
            "Train Epoch: 3 [42240/60000]\tLoss: -0.637953\n",
            "Train Epoch: 3 [42880/60000]\tLoss: -0.614751\n",
            "Train Epoch: 3 [43520/60000]\tLoss: -0.696186\n",
            "Train Epoch: 3 [44160/60000]\tLoss: -0.626360\n",
            "Train Epoch: 3 [44800/60000]\tLoss: -0.597461\n",
            "Train Epoch: 3 [45440/60000]\tLoss: -0.648344\n",
            "Train Epoch: 3 [46080/60000]\tLoss: -0.600610\n",
            "Train Epoch: 3 [46720/60000]\tLoss: -0.727930\n",
            "Train Epoch: 3 [47360/60000]\tLoss: -0.714098\n",
            "Train Epoch: 3 [48000/60000]\tLoss: -0.706536\n",
            "Train Epoch: 3 [48640/60000]\tLoss: -0.674529\n",
            "Train Epoch: 3 [49280/60000]\tLoss: -0.614188\n",
            "Train Epoch: 3 [49920/60000]\tLoss: -0.670839\n",
            "Train Epoch: 3 [50560/60000]\tLoss: -0.551926\n",
            "Train Epoch: 3 [51200/60000]\tLoss: -0.640029\n",
            "Train Epoch: 3 [51840/60000]\tLoss: -0.666716\n",
            "Train Epoch: 3 [52480/60000]\tLoss: -0.639799\n",
            "Train Epoch: 3 [53120/60000]\tLoss: -0.605904\n",
            "Train Epoch: 3 [53760/60000]\tLoss: -0.511029\n",
            "Train Epoch: 3 [54400/60000]\tLoss: -0.652450\n",
            "Train Epoch: 3 [55040/60000]\tLoss: -0.603215\n",
            "Train Epoch: 3 [55680/60000]\tLoss: -0.683557\n",
            "Train Epoch: 3 [56320/60000]\tLoss: -0.790670\n",
            "Train Epoch: 3 [56960/60000]\tLoss: -0.590700\n",
            "Train Epoch: 3 [57600/60000]\tLoss: -0.522989\n",
            "Train Epoch: 3 [58240/60000]\tLoss: -0.560746\n",
            "Train Epoch: 3 [58880/60000]\tLoss: -0.708147\n",
            "Train Epoch: 3 [59520/60000]\tLoss: -0.623321\n",
            "\n",
            "Test set: Avg. loss: -0.6615, Accuracy: 6631/10000 (66%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run network on data we got before and show predictions\n",
        "output = model(example_data)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(20):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Prediction: {}\".format(\n",
        "    output.data.max(1, keepdim=True)[1][i].item()))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o7fRUAy9Se1B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "83bfa177-abed-4a49-e076-76665c696605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2: TODO [45 Points]\n",
        "You implemented the previous given architecture. Now let's implement a modified version of AlexNet on mnist.\n",
        "\n",
        "if you don't know what alexnet is, don't worry. This lab doesn't require the background of it. Its just an architecture and we are implementing it.\n",
        "\n",
        "Here is AlexNet Architecture:\n",
        "1. Convolution with kernel size 5, stride 1, padding 1, 1 input channel and 32 output channels\n",
        "2. A Relu\n",
        "3. Convolution with kernel size 3, padding 1, 32 input channels and 64 output channels\n",
        "4. A Relu\n",
        "5. A max pooling operation over a 2x2 area, stride 2\n",
        "6. Convolution with kernel size 3, padding 1, 64 input channels and 96 output channels\n",
        "7. A Relu\n",
        "8. Convolution with kernel size 3, padding 1, 96 input channels and 64 output channels\n",
        "9. A Relu\n",
        "10. Convolution with kernel size 3, padding 1, 64 input channels and 32 output channels\n",
        "11. A Relu\n",
        "12. A max pooling operation over a 2x2 area, stride 1\n",
        "\n",
        "13. A flattening operation\n",
        "14. A dropout\n",
        "15. A fully connected layer mapping from (whatever dimensions we are at-- find out using .shape) to 2048\n",
        "16. A ReLU\n",
        "11. A fully connected layer mapping from 2048 to 1024\n",
        "16. A ReLU\n",
        "18. A fully connected layer mapping from 1024 to 10\n",
        "\n",
        "\n",
        "\n",
        "            \n"
      ],
      "metadata": {
        "id": "bv64TOPCixo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num=10):\n",
        "        super(Net, self).__init__()\n",
        "        self.model=nn.Sequential(\n",
        "\n",
        "            #nn.MaxPool2d( kernel_size=2, stride=2) This code can be used for max pooling. Google it to understand it.\n",
        "            #nn.Dropout() can be used for dropout\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d( kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=96, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d( kernel_size=2, stride=1),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(in_features=4608, out_features=2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=2048, out_features=1024),\n",
        "            nn.ReLU(),\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QU5QKT9Gk6DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Do NOT EDIT\n",
        "#USE THIS CODE FOR TESTING\n",
        "#Since we can't compare the model, its better to look at the its printed structure and compare it with layers given in architecture\n",
        "model = Net()\n",
        "print(model)\n",
        "\n",
        "model.apply(weights_init)\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n"
      ],
      "metadata": {
        "id": "Sy48-WOKpOPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c8f7a5-237f-408a-f52c-fd7f9df21bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU()\n",
            "    (7): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU()\n",
            "    (9): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU()\n",
            "    (11): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Flatten(start_dim=1, end_dim=-1)\n",
            "    (13): Dropout(p=0.5, inplace=False)\n",
            "    (14): Linear(in_features=4608, out_features=2048, bias=True)\n",
            "    (15): ReLU()\n",
            "    (16): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (17): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training routine\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  # Get each\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    if torch.cuda.is_available():\n",
        "      data, target = data.cuda(), target.cuda()\n",
        "    data, target = Variable(data), Variable(target)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.cross_entropy(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # Store results\n",
        "    if batch_idx % 10 == 0:\n",
        "      print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset), loss.item()))"
      ],
      "metadata": {
        "id": "rG-0q_GiGWCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run on test data\n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "      if torch.cuda.is_available():\n",
        "          data, target = data.cuda(), target.cuda()\n",
        "      data, target = Variable(data, volatile=True), Variable(target)\n",
        "      output = model(data)\n",
        "      test_loss += F.cross_entropy(output, target, size_average=False).item()# sum up batch loss\n",
        "      pred = output.data.max(1, keepdim=True)[1]# get the index of the max log-probability\n",
        "      correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  correct=float(correct.to(torch.device('cpu')).numpy())\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "Rn0y3e5GGcNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for three epochs\n",
        "n_epochs = 3\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "id": "hctfpGLkGlCN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcdd213b-ccff-453b-fe25-a95adbda3efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000]\tLoss: 6.923129\n",
            "Train Epoch: 1 [640/60000]\tLoss: 6.798572\n",
            "Train Epoch: 1 [1280/60000]\tLoss: 3.290431\n",
            "Train Epoch: 1 [1920/60000]\tLoss: 2.395129\n",
            "Train Epoch: 1 [2560/60000]\tLoss: 1.872373\n",
            "Train Epoch: 1 [3200/60000]\tLoss: 1.268274\n",
            "Train Epoch: 1 [3840/60000]\tLoss: 1.203794\n",
            "Train Epoch: 1 [4480/60000]\tLoss: 0.894927\n",
            "Train Epoch: 1 [5120/60000]\tLoss: 0.859196\n",
            "Train Epoch: 1 [5760/60000]\tLoss: 0.800074\n",
            "Train Epoch: 1 [6400/60000]\tLoss: 0.557511\n",
            "Train Epoch: 1 [7040/60000]\tLoss: 0.592501\n",
            "Train Epoch: 1 [7680/60000]\tLoss: 0.793631\n",
            "Train Epoch: 1 [8320/60000]\tLoss: 0.531639\n",
            "Train Epoch: 1 [8960/60000]\tLoss: 0.510054\n",
            "Train Epoch: 1 [9600/60000]\tLoss: 0.422347\n",
            "Train Epoch: 1 [10240/60000]\tLoss: 0.326470\n",
            "Train Epoch: 1 [10880/60000]\tLoss: 0.504179\n",
            "Train Epoch: 1 [11520/60000]\tLoss: 0.283084\n",
            "Train Epoch: 1 [12160/60000]\tLoss: 0.434632\n",
            "Train Epoch: 1 [12800/60000]\tLoss: 0.188305\n",
            "Train Epoch: 1 [13440/60000]\tLoss: 0.357731\n",
            "Train Epoch: 1 [14080/60000]\tLoss: 0.409375\n",
            "Train Epoch: 1 [14720/60000]\tLoss: 0.275489\n",
            "Train Epoch: 1 [15360/60000]\tLoss: 0.200244\n",
            "Train Epoch: 1 [16000/60000]\tLoss: 0.397282\n",
            "Train Epoch: 1 [16640/60000]\tLoss: 0.335716\n",
            "Train Epoch: 1 [17280/60000]\tLoss: 0.246837\n",
            "Train Epoch: 1 [17920/60000]\tLoss: 0.397008\n",
            "Train Epoch: 1 [18560/60000]\tLoss: 0.463819\n",
            "Train Epoch: 1 [19200/60000]\tLoss: 0.245134\n",
            "Train Epoch: 1 [19840/60000]\tLoss: 0.178690\n",
            "Train Epoch: 1 [20480/60000]\tLoss: 0.142930\n",
            "Train Epoch: 1 [21120/60000]\tLoss: 0.294413\n",
            "Train Epoch: 1 [21760/60000]\tLoss: 0.140919\n",
            "Train Epoch: 1 [22400/60000]\tLoss: 0.173051\n",
            "Train Epoch: 1 [23040/60000]\tLoss: 0.234560\n",
            "Train Epoch: 1 [23680/60000]\tLoss: 0.615871\n",
            "Train Epoch: 1 [24320/60000]\tLoss: 0.178672\n",
            "Train Epoch: 1 [24960/60000]\tLoss: 0.099854\n",
            "Train Epoch: 1 [25600/60000]\tLoss: 0.188575\n",
            "Train Epoch: 1 [26240/60000]\tLoss: 0.162812\n",
            "Train Epoch: 1 [26880/60000]\tLoss: 0.158587\n",
            "Train Epoch: 1 [27520/60000]\tLoss: 0.332400\n",
            "Train Epoch: 1 [28160/60000]\tLoss: 0.198939\n",
            "Train Epoch: 1 [28800/60000]\tLoss: 0.336795\n",
            "Train Epoch: 1 [29440/60000]\tLoss: 0.077688\n",
            "Train Epoch: 1 [30080/60000]\tLoss: 0.128681\n",
            "Train Epoch: 1 [30720/60000]\tLoss: 0.112202\n",
            "Train Epoch: 1 [31360/60000]\tLoss: 0.170200\n",
            "Train Epoch: 1 [32000/60000]\tLoss: 0.178138\n",
            "Train Epoch: 1 [32640/60000]\tLoss: 0.156214\n",
            "Train Epoch: 1 [33280/60000]\tLoss: 0.209781\n",
            "Train Epoch: 1 [33920/60000]\tLoss: 0.194740\n",
            "Train Epoch: 1 [34560/60000]\tLoss: 0.213538\n",
            "Train Epoch: 1 [35200/60000]\tLoss: 0.096860\n",
            "Train Epoch: 1 [35840/60000]\tLoss: 0.086342\n",
            "Train Epoch: 1 [36480/60000]\tLoss: 0.085987\n",
            "Train Epoch: 1 [37120/60000]\tLoss: 0.146402\n",
            "Train Epoch: 1 [37760/60000]\tLoss: 0.174645\n",
            "Train Epoch: 1 [38400/60000]\tLoss: 0.039866\n",
            "Train Epoch: 1 [39040/60000]\tLoss: 0.182980\n",
            "Train Epoch: 1 [39680/60000]\tLoss: 0.137405\n",
            "Train Epoch: 1 [40320/60000]\tLoss: 0.204628\n",
            "Train Epoch: 1 [40960/60000]\tLoss: 0.158949\n",
            "Train Epoch: 1 [41600/60000]\tLoss: 0.113140\n",
            "Train Epoch: 1 [42240/60000]\tLoss: 0.180388\n",
            "Train Epoch: 1 [42880/60000]\tLoss: 0.133033\n",
            "Train Epoch: 1 [43520/60000]\tLoss: 0.080895\n",
            "Train Epoch: 1 [44160/60000]\tLoss: 0.199442\n",
            "Train Epoch: 1 [44800/60000]\tLoss: 0.222303\n",
            "Train Epoch: 1 [45440/60000]\tLoss: 0.032784\n",
            "Train Epoch: 1 [46080/60000]\tLoss: 0.122609\n",
            "Train Epoch: 1 [46720/60000]\tLoss: 0.084565\n",
            "Train Epoch: 1 [47360/60000]\tLoss: 0.127599\n",
            "Train Epoch: 1 [48000/60000]\tLoss: 0.146592\n",
            "Train Epoch: 1 [48640/60000]\tLoss: 0.061549\n",
            "Train Epoch: 1 [49280/60000]\tLoss: 0.063335\n",
            "Train Epoch: 1 [49920/60000]\tLoss: 0.152610\n",
            "Train Epoch: 1 [50560/60000]\tLoss: 0.251732\n",
            "Train Epoch: 1 [51200/60000]\tLoss: 0.081091\n",
            "Train Epoch: 1 [51840/60000]\tLoss: 0.164196\n",
            "Train Epoch: 1 [52480/60000]\tLoss: 0.099590\n",
            "Train Epoch: 1 [53120/60000]\tLoss: 0.257646\n",
            "Train Epoch: 1 [53760/60000]\tLoss: 0.046223\n",
            "Train Epoch: 1 [54400/60000]\tLoss: 0.064739\n",
            "Train Epoch: 1 [55040/60000]\tLoss: 0.168296\n",
            "Train Epoch: 1 [55680/60000]\tLoss: 0.114547\n",
            "Train Epoch: 1 [56320/60000]\tLoss: 0.117345\n",
            "Train Epoch: 1 [56960/60000]\tLoss: 0.120939\n",
            "Train Epoch: 1 [57600/60000]\tLoss: 0.070056\n",
            "Train Epoch: 1 [58240/60000]\tLoss: 0.085815\n",
            "Train Epoch: 1 [58880/60000]\tLoss: 0.047697\n",
            "Train Epoch: 1 [59520/60000]\tLoss: 0.063415\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-61-0b1ccd3c1330>:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  data, target = Variable(data, volatile=True), Variable(target)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Avg. loss: 0.0732, Accuracy: 9770.0/10000 (98%)\n",
            "\n",
            "Train Epoch: 2 [0/60000]\tLoss: 0.093361\n",
            "Train Epoch: 2 [640/60000]\tLoss: 0.093536\n",
            "Train Epoch: 2 [1280/60000]\tLoss: 0.082704\n",
            "Train Epoch: 2 [1920/60000]\tLoss: 0.048194\n",
            "Train Epoch: 2 [2560/60000]\tLoss: 0.154863\n",
            "Train Epoch: 2 [3200/60000]\tLoss: 0.044351\n",
            "Train Epoch: 2 [3840/60000]\tLoss: 0.021106\n",
            "Train Epoch: 2 [4480/60000]\tLoss: 0.146539\n",
            "Train Epoch: 2 [5120/60000]\tLoss: 0.089017\n",
            "Train Epoch: 2 [5760/60000]\tLoss: 0.082675\n",
            "Train Epoch: 2 [6400/60000]\tLoss: 0.314443\n",
            "Train Epoch: 2 [7040/60000]\tLoss: 0.074070\n",
            "Train Epoch: 2 [7680/60000]\tLoss: 0.138722\n",
            "Train Epoch: 2 [8320/60000]\tLoss: 0.082863\n",
            "Train Epoch: 2 [8960/60000]\tLoss: 0.035468\n",
            "Train Epoch: 2 [9600/60000]\tLoss: 0.052624\n",
            "Train Epoch: 2 [10240/60000]\tLoss: 0.069696\n",
            "Train Epoch: 2 [10880/60000]\tLoss: 0.118315\n",
            "Train Epoch: 2 [11520/60000]\tLoss: 0.140394\n",
            "Train Epoch: 2 [12160/60000]\tLoss: 0.078458\n",
            "Train Epoch: 2 [12800/60000]\tLoss: 0.029025\n",
            "Train Epoch: 2 [13440/60000]\tLoss: 0.043953\n",
            "Train Epoch: 2 [14080/60000]\tLoss: 0.155840\n",
            "Train Epoch: 2 [14720/60000]\tLoss: 0.113869\n",
            "Train Epoch: 2 [15360/60000]\tLoss: 0.036957\n",
            "Train Epoch: 2 [16000/60000]\tLoss: 0.034228\n",
            "Train Epoch: 2 [16640/60000]\tLoss: 0.209952\n",
            "Train Epoch: 2 [17280/60000]\tLoss: 0.039983\n",
            "Train Epoch: 2 [17920/60000]\tLoss: 0.086651\n",
            "Train Epoch: 2 [18560/60000]\tLoss: 0.117478\n",
            "Train Epoch: 2 [19200/60000]\tLoss: 0.121588\n",
            "Train Epoch: 2 [19840/60000]\tLoss: 0.016960\n",
            "Train Epoch: 2 [20480/60000]\tLoss: 0.203563\n",
            "Train Epoch: 2 [21120/60000]\tLoss: 0.051634\n",
            "Train Epoch: 2 [21760/60000]\tLoss: 0.046122\n",
            "Train Epoch: 2 [22400/60000]\tLoss: 0.089897\n",
            "Train Epoch: 2 [23040/60000]\tLoss: 0.110596\n",
            "Train Epoch: 2 [23680/60000]\tLoss: 0.288195\n",
            "Train Epoch: 2 [24320/60000]\tLoss: 0.092351\n",
            "Train Epoch: 2 [24960/60000]\tLoss: 0.035383\n",
            "Train Epoch: 2 [25600/60000]\tLoss: 0.102024\n",
            "Train Epoch: 2 [26240/60000]\tLoss: 0.018122\n",
            "Train Epoch: 2 [26880/60000]\tLoss: 0.104411\n",
            "Train Epoch: 2 [27520/60000]\tLoss: 0.057334\n",
            "Train Epoch: 2 [28160/60000]\tLoss: 0.062257\n",
            "Train Epoch: 2 [28800/60000]\tLoss: 0.064135\n",
            "Train Epoch: 2 [29440/60000]\tLoss: 0.071365\n",
            "Train Epoch: 2 [30080/60000]\tLoss: 0.062528\n",
            "Train Epoch: 2 [30720/60000]\tLoss: 0.092675\n",
            "Train Epoch: 2 [31360/60000]\tLoss: 0.131193\n",
            "Train Epoch: 2 [32000/60000]\tLoss: 0.106972\n",
            "Train Epoch: 2 [32640/60000]\tLoss: 0.131769\n",
            "Train Epoch: 2 [33280/60000]\tLoss: 0.025726\n",
            "Train Epoch: 2 [33920/60000]\tLoss: 0.101577\n",
            "Train Epoch: 2 [34560/60000]\tLoss: 0.101510\n",
            "Train Epoch: 2 [35200/60000]\tLoss: 0.116995\n",
            "Train Epoch: 2 [35840/60000]\tLoss: 0.100157\n",
            "Train Epoch: 2 [36480/60000]\tLoss: 0.043152\n",
            "Train Epoch: 2 [37120/60000]\tLoss: 0.121742\n",
            "Train Epoch: 2 [37760/60000]\tLoss: 0.230059\n",
            "Train Epoch: 2 [38400/60000]\tLoss: 0.130301\n",
            "Train Epoch: 2 [39040/60000]\tLoss: 0.073185\n",
            "Train Epoch: 2 [39680/60000]\tLoss: 0.031480\n",
            "Train Epoch: 2 [40320/60000]\tLoss: 0.078187\n",
            "Train Epoch: 2 [40960/60000]\tLoss: 0.041762\n",
            "Train Epoch: 2 [41600/60000]\tLoss: 0.255025\n",
            "Train Epoch: 2 [42240/60000]\tLoss: 0.067437\n",
            "Train Epoch: 2 [42880/60000]\tLoss: 0.083365\n",
            "Train Epoch: 2 [43520/60000]\tLoss: 0.091301\n",
            "Train Epoch: 2 [44160/60000]\tLoss: 0.071625\n",
            "Train Epoch: 2 [44800/60000]\tLoss: 0.065057\n",
            "Train Epoch: 2 [45440/60000]\tLoss: 0.029552\n",
            "Train Epoch: 2 [46080/60000]\tLoss: 0.111646\n",
            "Train Epoch: 2 [46720/60000]\tLoss: 0.079379\n",
            "Train Epoch: 2 [47360/60000]\tLoss: 0.162318\n",
            "Train Epoch: 2 [48000/60000]\tLoss: 0.056517\n",
            "Train Epoch: 2 [48640/60000]\tLoss: 0.051292\n",
            "Train Epoch: 2 [49280/60000]\tLoss: 0.112208\n",
            "Train Epoch: 2 [49920/60000]\tLoss: 0.042947\n",
            "Train Epoch: 2 [50560/60000]\tLoss: 0.060371\n",
            "Train Epoch: 2 [51200/60000]\tLoss: 0.152514\n",
            "Train Epoch: 2 [51840/60000]\tLoss: 0.119763\n",
            "Train Epoch: 2 [52480/60000]\tLoss: 0.044507\n",
            "Train Epoch: 2 [53120/60000]\tLoss: 0.039322\n",
            "Train Epoch: 2 [53760/60000]\tLoss: 0.044328\n",
            "Train Epoch: 2 [54400/60000]\tLoss: 0.010829\n",
            "Train Epoch: 2 [55040/60000]\tLoss: 0.140528\n",
            "Train Epoch: 2 [55680/60000]\tLoss: 0.129224\n",
            "Train Epoch: 2 [56320/60000]\tLoss: 0.124829\n",
            "Train Epoch: 2 [56960/60000]\tLoss: 0.065912\n",
            "Train Epoch: 2 [57600/60000]\tLoss: 0.118716\n",
            "Train Epoch: 2 [58240/60000]\tLoss: 0.122095\n",
            "Train Epoch: 2 [58880/60000]\tLoss: 0.157564\n",
            "Train Epoch: 2 [59520/60000]\tLoss: 0.101043\n",
            "\n",
            "Test set: Avg. loss: 0.0444, Accuracy: 9846.0/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/60000]\tLoss: 0.084990\n",
            "Train Epoch: 3 [640/60000]\tLoss: 0.016773\n",
            "Train Epoch: 3 [1280/60000]\tLoss: 0.038366\n",
            "Train Epoch: 3 [1920/60000]\tLoss: 0.043396\n",
            "Train Epoch: 3 [2560/60000]\tLoss: 0.174078\n",
            "Train Epoch: 3 [3200/60000]\tLoss: 0.064759\n",
            "Train Epoch: 3 [3840/60000]\tLoss: 0.064714\n",
            "Train Epoch: 3 [4480/60000]\tLoss: 0.032459\n",
            "Train Epoch: 3 [5120/60000]\tLoss: 0.022247\n",
            "Train Epoch: 3 [5760/60000]\tLoss: 0.037036\n",
            "Train Epoch: 3 [6400/60000]\tLoss: 0.073352\n",
            "Train Epoch: 3 [7040/60000]\tLoss: 0.113359\n",
            "Train Epoch: 3 [7680/60000]\tLoss: 0.191427\n",
            "Train Epoch: 3 [8320/60000]\tLoss: 0.018977\n",
            "Train Epoch: 3 [8960/60000]\tLoss: 0.064185\n",
            "Train Epoch: 3 [9600/60000]\tLoss: 0.200723\n",
            "Train Epoch: 3 [10240/60000]\tLoss: 0.009887\n",
            "Train Epoch: 3 [10880/60000]\tLoss: 0.107178\n",
            "Train Epoch: 3 [11520/60000]\tLoss: 0.032362\n",
            "Train Epoch: 3 [12160/60000]\tLoss: 0.016734\n",
            "Train Epoch: 3 [12800/60000]\tLoss: 0.100702\n",
            "Train Epoch: 3 [13440/60000]\tLoss: 0.013963\n",
            "Train Epoch: 3 [14080/60000]\tLoss: 0.072740\n",
            "Train Epoch: 3 [14720/60000]\tLoss: 0.051977\n",
            "Train Epoch: 3 [15360/60000]\tLoss: 0.062578\n",
            "Train Epoch: 3 [16000/60000]\tLoss: 0.036859\n",
            "Train Epoch: 3 [16640/60000]\tLoss: 0.075334\n",
            "Train Epoch: 3 [17280/60000]\tLoss: 0.017715\n",
            "Train Epoch: 3 [17920/60000]\tLoss: 0.164405\n",
            "Train Epoch: 3 [18560/60000]\tLoss: 0.041610\n",
            "Train Epoch: 3 [19200/60000]\tLoss: 0.036585\n",
            "Train Epoch: 3 [19840/60000]\tLoss: 0.129798\n",
            "Train Epoch: 3 [20480/60000]\tLoss: 0.016748\n",
            "Train Epoch: 3 [21120/60000]\tLoss: 0.063008\n",
            "Train Epoch: 3 [21760/60000]\tLoss: 0.025846\n",
            "Train Epoch: 3 [22400/60000]\tLoss: 0.057115\n",
            "Train Epoch: 3 [23040/60000]\tLoss: 0.049438\n",
            "Train Epoch: 3 [23680/60000]\tLoss: 0.131146\n",
            "Train Epoch: 3 [24320/60000]\tLoss: 0.053106\n",
            "Train Epoch: 3 [24960/60000]\tLoss: 0.026900\n",
            "Train Epoch: 3 [25600/60000]\tLoss: 0.046447\n",
            "Train Epoch: 3 [26240/60000]\tLoss: 0.085454\n",
            "Train Epoch: 3 [26880/60000]\tLoss: 0.015018\n",
            "Train Epoch: 3 [27520/60000]\tLoss: 0.054131\n",
            "Train Epoch: 3 [28160/60000]\tLoss: 0.155676\n",
            "Train Epoch: 3 [28800/60000]\tLoss: 0.023008\n",
            "Train Epoch: 3 [29440/60000]\tLoss: 0.085284\n",
            "Train Epoch: 3 [30080/60000]\tLoss: 0.077275\n",
            "Train Epoch: 3 [30720/60000]\tLoss: 0.057802\n",
            "Train Epoch: 3 [31360/60000]\tLoss: 0.068696\n",
            "Train Epoch: 3 [32000/60000]\tLoss: 0.057186\n",
            "Train Epoch: 3 [32640/60000]\tLoss: 0.051267\n",
            "Train Epoch: 3 [33280/60000]\tLoss: 0.108825\n",
            "Train Epoch: 3 [33920/60000]\tLoss: 0.096122\n",
            "Train Epoch: 3 [34560/60000]\tLoss: 0.035968\n",
            "Train Epoch: 3 [35200/60000]\tLoss: 0.093356\n",
            "Train Epoch: 3 [35840/60000]\tLoss: 0.023068\n",
            "Train Epoch: 3 [36480/60000]\tLoss: 0.053885\n",
            "Train Epoch: 3 [37120/60000]\tLoss: 0.097010\n",
            "Train Epoch: 3 [37760/60000]\tLoss: 0.039505\n",
            "Train Epoch: 3 [38400/60000]\tLoss: 0.015876\n",
            "Train Epoch: 3 [39040/60000]\tLoss: 0.092575\n",
            "Train Epoch: 3 [39680/60000]\tLoss: 0.086746\n",
            "Train Epoch: 3 [40320/60000]\tLoss: 0.087794\n",
            "Train Epoch: 3 [40960/60000]\tLoss: 0.005891\n",
            "Train Epoch: 3 [41600/60000]\tLoss: 0.018522\n",
            "Train Epoch: 3 [42240/60000]\tLoss: 0.020806\n",
            "Train Epoch: 3 [42880/60000]\tLoss: 0.049488\n",
            "Train Epoch: 3 [43520/60000]\tLoss: 0.058361\n",
            "Train Epoch: 3 [44160/60000]\tLoss: 0.145270\n",
            "Train Epoch: 3 [44800/60000]\tLoss: 0.003720\n",
            "Train Epoch: 3 [45440/60000]\tLoss: 0.162923\n",
            "Train Epoch: 3 [46080/60000]\tLoss: 0.032226\n",
            "Train Epoch: 3 [46720/60000]\tLoss: 0.034764\n",
            "Train Epoch: 3 [47360/60000]\tLoss: 0.052518\n",
            "Train Epoch: 3 [48000/60000]\tLoss: 0.064146\n",
            "Train Epoch: 3 [48640/60000]\tLoss: 0.065570\n",
            "Train Epoch: 3 [49280/60000]\tLoss: 0.046992\n",
            "Train Epoch: 3 [49920/60000]\tLoss: 0.070933\n",
            "Train Epoch: 3 [50560/60000]\tLoss: 0.079630\n",
            "Train Epoch: 3 [51200/60000]\tLoss: 0.044105\n",
            "Train Epoch: 3 [51840/60000]\tLoss: 0.054605\n",
            "Train Epoch: 3 [52480/60000]\tLoss: 0.130462\n",
            "Train Epoch: 3 [53120/60000]\tLoss: 0.042535\n",
            "Train Epoch: 3 [53760/60000]\tLoss: 0.127827\n",
            "Train Epoch: 3 [54400/60000]\tLoss: 0.260185\n",
            "Train Epoch: 3 [55040/60000]\tLoss: 0.121987\n",
            "Train Epoch: 3 [55680/60000]\tLoss: 0.110166\n",
            "Train Epoch: 3 [56320/60000]\tLoss: 0.024791\n",
            "Train Epoch: 3 [56960/60000]\tLoss: 0.099184\n",
            "Train Epoch: 3 [57600/60000]\tLoss: 0.031305\n",
            "Train Epoch: 3 [58240/60000]\tLoss: 0.057515\n",
            "Train Epoch: 3 [58880/60000]\tLoss: 0.042566\n",
            "Train Epoch: 3 [59520/60000]\tLoss: 0.010393\n",
            "\n",
            "Test set: Avg. loss: 0.0368, Accuracy: 9874.0/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run network on data we got before and show predictions\n",
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_target) = next(examples)\n",
        "if torch.cuda.is_available():\n",
        "  example_data, example_target = example_data.cuda(), example_target.cuda()\n",
        "example_data, example_target = Variable(example_data, volatile=True), Variable(example_target)\n",
        "output = model(example_data)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(20):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0].cpu(), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Prediction: {}\".format(\n",
        "    output.data.max(1, keepdim=True)[1][i].item()))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dC13J2PKGoJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3: TODO [25 Points]\n",
        "Try 2 additional techniques\n",
        "1. Data augmentation for increasing data\n",
        "2. Number of epochs\n",
        "3. Batch size in dataloader\n",
        "\n",
        "implement this under this cell and give your opinion about does data augmentation helps in improving accuracy. WHat effetc does changing epochs have on the training. What effect did changing batch size have.\n",
        "You can utilize AI Tools for this as well."
      ],
      "metadata": {
        "id": "7QjgeQ40nPnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data Augmentation, Epochs, and Batch Size\n",
        "batch_size_train = 128  # Modified batch size\n",
        "batch_size_test = 1000\n",
        "n_epochs = 5  # Modified number of epochs\n",
        "\n",
        "# Data Loaders with Augmentation\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.RandomRotation(10),\n",
        "                                   transforms.RandomHorizontalFlip(),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.1307,), (0.3081,))\n",
        "                               ])),\n",
        "    batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.1307,), (0.3081,))\n",
        "                               ])),\n",
        "    batch_size=batch_size_test, shuffle=True)\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "++++\n",
        "# Train the model\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    train(epoch)\n",
        "    test()\n"
      ],
      "metadata": {
        "id": "-9RKnxTq3FJj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "otter": {
      "tests": {
        "Task01": {
          "name": "Task01",
          "points": 10,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Task02": {
          "name": "Task02",
          "points": 20,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Task03": {
          "name": "Task03",
          "points": 10,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Task04": {
          "name": "Task04",
          "points": 20,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Task05": {
          "name": "Task05",
          "points": 20,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Task06": {
          "name": "Task06",
          "points": 20,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        }
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "341ce806ad348c6396969bf6bfc3e3b2899dcbddac3f00a64251096e015967a2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}